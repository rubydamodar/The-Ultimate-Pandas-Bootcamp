{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you're in a classroom. The Pandas DataFrame is like a class register (attendance book). In that register:\n",
    "\n",
    "- The rows are like students in your class.\n",
    "- The columns are like the subjects each student has. For example: one column for \"Name\", another for \"Math marks\", one for \"Science marks\", etc.\n",
    "- The index is like the roll numbers assigned to each student.\n",
    "So, the Pandas DataFrame is nothing but a table that helps you organize your data in rows and columns, exactly like how you maintain school or college records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame is basically a 2D (two-dimensional) data structure in Pandas, meaning it has both rows and columns. It's one of the most important parts of Pandas, which is why we focus on it so much.\n",
    "\n",
    "- Just like your class register has names and marks of students, a DataFrame holds labeled data.\n",
    "- You can store different types of data in one DataFrame: numbers, strings (like names), dates, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Simple DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's say you want to create a DataFrame for a class with details of 3 students, their marks in Math, and the city they are from. In Pandas, you can do this using Python, and it’s as simple as writing the names and marks in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a simple DataFrame in Pandas, you can use various data structures like lists, dictionaries, or even external data sources such as CSV files or databases. Let's start with the basics of DataFrame creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a DataFrame from a Dictionary\n",
    "we are familiar with storing data in tabular forms like a school attendance register. Consider a dictionary as something like a record where each key is a \"column heading\" and the values are lists of \"entries\" in that column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Student details in a classroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age       City\n",
      "0   Aman   16      Delhi\n",
      "1  Priya   17     Mumbai\n",
      "2    Raj   16  Bangalore\n",
      "3  Sneha   18    Chennai\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data as a dictionary\n",
    "student_data = {\n",
    "    'Name': ['Aman', 'Priya', 'Raj', 'Sneha'],\n",
    "    'Age': [16, 17, 16, 18],\n",
    "    'City': ['Delhi', 'Mumbai', 'Bangalore', 'Chennai']\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(student_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name, Age, City are like the headings of our columns, just like a ledger's headings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are the actual data, similar to entries in each student's row in your school register."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a DataFrame from a List of Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of a list of lists as a table with rows of data. It's like when you jot down data in rows in your notebook for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age       City\n",
      "0   Aman   16      Delhi\n",
      "1  Priya   17     Mumbai\n",
      "2    Raj   16  Bangalore\n",
      "3  Sneha   18    Chennai\n"
     ]
    }
   ],
   "source": [
    "# List of lists where each list is a row (student's data)\n",
    "data = [\n",
    "    ['Aman', 16, 'Delhi'],\n",
    "    ['Priya', 17, 'Mumbai'],\n",
    "    ['Raj', 16, 'Bangalore'],\n",
    "    ['Sneha', 18, 'Chennai']\n",
    "]\n",
    "\n",
    "# Create DataFrame and specify column labels\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age', 'City'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each inner list represents a row, which is like a complete entry for a student in the class. It’s just like making rows in a notebook for student records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a DataFrame from a List of Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age       City\n",
      "0   Aman   16      Delhi\n",
      "1  Priya   17     Mumbai\n",
      "2    Raj   16  Bangalore\n",
      "3  Sneha   18    Chennai\n"
     ]
    }
   ],
   "source": [
    "# List of dictionaries where each dictionary is a row\n",
    "family_data = [\n",
    "    {'Name': 'Aman', 'Age': 16, 'City': 'Delhi'},\n",
    "    {'Name': 'Priya', 'Age': 17, 'City': 'Mumbai'},\n",
    "    {'Name': 'Raj', 'Age': 16, 'City': 'Bangalore'},\n",
    "    {'Name': 'Sneha', 'Age': 18, 'City': 'Chennai'}\n",
    "]\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "df = pd.DataFrame(family_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dictionary can be seen as a person’s record, much like writing an entry for each person in a family or an office group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a DataFrame from NumPy Arrays\n",
    "In India, we often deal with numbers, such as exam scores or bank transactions. Using NumPy arrays, we can store numerical data efficiently. Let’s create a DataFrame from NumPy arrays, much like a marksheet of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Marks       City\n",
      "0   Aman     85      Delhi\n",
      "1  Priya     90     Mumbai\n",
      "2    Raj     78  Bangalore\n",
      "3  Sneha     88    Chennai\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create NumPy arrays for data\n",
    "names = np.array(['Aman', 'Priya', 'Raj', 'Sneha'])\n",
    "marks = np.array([85, 90, 78, 88])\n",
    "cities = np.array(['Delhi', 'Mumbai', 'Bangalore', 'Chennai'])\n",
    "\n",
    "# Create DataFrame from NumPy arrays\n",
    "df = pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'Marks': marks,\n",
    "    'City': cities\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, NumPy arrays are used to hold data, just like a marksheet with names and scores. In this case, each array holds a column of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating DataFrame from CSV or Excel files\n",
    "In real life, we often store data in Excel or CSV files, like monthly electricity bills or bank statements. Pandas makes it very easy to read data from these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading from a CSV file (file needs to be present in your system)\n",
    "df = pd.read_csv('students_data.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, Pandas will load the CSV file data into a DataFrame, just like copying the table from Excel into Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Accessing a Single Column (Like looking at a specific category in your notebook)\n",
    "When you want to check a specific column, such as names, ages, or marks, it’s like checking only one subject or column in your register.\n",
    "\n",
    "Example: Student Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha'],\n",
    "    'Age': [18, 17, 19, 18],\n",
    "    'Marks': [85, 92, 75, 88]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks\n",
      "0   Rahul   18     85\n",
      "1  Anjali   17     92\n",
      "2  Sameer   19     75\n",
      "3    Neha   18     88\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing a column by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Rahul\n",
      "1    Anjali\n",
      "2    Sameer\n",
      "3      Neha\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Access the 'Name' column\n",
    "print(df['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you’re just looking at the \"Name\" column, like how you’d open your school register and look at all students’ names. You’re focusing on that one specific column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Accessing Multiple Columns (Like checking multiple subjects at once)\n",
    "You can access more than one column at the same time, similar to looking at both names and marks in your register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Marks\n",
      "0   Rahul     85\n",
      "1  Anjali     92\n",
      "2  Sameer     75\n",
      "3    Neha     88\n"
     ]
    }
   ],
   "source": [
    "# Accessing multiple columns ('Name' and 'Marks')\n",
    "print(df[['Name', 'Marks']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you're pulling out both the Name and Marks columns—like checking both subjects in your register at the same time. You’re essentially selecting two columns from the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accessing Rows by Index (Looking at a specific student's details)\n",
    "If you want to see all details of one particular student (like Rahul), you would find his row in the register.\n",
    "\n",
    "Accessing a row by index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name     Rahul\n",
      "Age         18\n",
      "Marks       85\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Accessing the first row (Rahul's data)\n",
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is like saying, \"Tell me all about the first student in the register.\" You’re getting the entire row—Name, Age, and Marks—for that student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accessing Rows by Label with .loc[]\n",
    "Pandas has this nice .loc[] method, which allows you to access data by its label (row index). Think of it like referring to a page number or entry number in your notebook.\n",
    "\n",
    "Accessing multiple rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks\n",
      "0   Rahul   18     85\n",
      "1  Anjali   17     92\n"
     ]
    }
   ],
   "source": [
    "# Access the rows of Rahul and Anjali\n",
    "print(df.loc[[0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re asking for all the details of Rahul and Anjali, just like reading two lines from your school register that contain all details for those students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Accessing a Specific Value (Looking at one piece of information)\n",
    "Let’s say you want to know Anjali’s Marks. You’ll need to go to Anjali's row and look under the Marks column, just like in your register.\n",
    "\n",
    "Accessing a specific value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "# Access Anjali's Marks\n",
    "print(df.loc[1, 'Marks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re looking for the Marks of the student at index 1 (Anjali). Just like finding Anjali in the school record and checking her marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Slicing (Accessing a range of rows and columns)\n",
    "Sometimes, you might want to look at multiple students and focus on particular subjects, like how you’d look at rows 2 to 4 and only focus on Name and Marks.\n",
    "\n",
    "Example: Access a slice of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Marks\n",
      "1  Anjali     92\n",
      "2  Sameer     75\n",
      "3    Neha     88\n"
     ]
    }
   ],
   "source": [
    "# Get a slice of the DataFrame (2nd to 4th rows, and 'Name' & 'Marks' columns)\n",
    "print(df.loc[1:3, ['Name', 'Marks']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is like reading Anjali, Sameer, and Neha’s names and marks only, leaving out the other details. You’ve sliced a portion of the DataFrame to focus on specific rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Accessing by Position Using .iloc[] (Like accessing by row number)\n",
    "Sometimes you don't know the labels, but you know the positions. For instance, you just want to check the 2nd student’s marks without caring about their name. .iloc[] helps you access rows and columns based on their position (just like row numbers in a notebook).\n",
    "\n",
    "Example: Access row and column by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "# Access the value in the second row and third column (Sameer’s marks)\n",
    "print(df.iloc[2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are saying, \"Show me the value in the 2nd row (Sameer) and the 3rd column (Marks).\" It’s like going to row 3 of your register and looking at a specific column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Accessing Multiple Rows and Columns with .iloc[]\n",
    "You can also use .iloc[] to get multiple rows and columns at the same time, much like checking several lines in your notebook.\n",
    "\n",
    "Example: Access multiple rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age\n",
      "1  Anjali   17\n",
      "2  Sameer   19\n",
      "3    Neha   18\n"
     ]
    }
   ],
   "source": [
    "# Access rows 1 to 3 and columns 1 to 2\n",
    "print(df.iloc[1:4, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re asking for the Name and Age of students from the 2nd to 4th rows, just like selecting a portion of your register."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conditional Access (Filtering data based on conditions)\n",
    "If your teacher asks, \"Show me students who scored more than 80 marks,\" you'd manually go through the register and note down the names of students meeting that condition. In Pandas, we can easily filter data based on conditions.\n",
    "\n",
    "Example: Access students who scored more than 80 marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks\n",
      "0   Rahul   18     85\n",
      "1  Anjali   17     92\n",
      "3    Neha   18     88\n"
     ]
    }
   ],
   "source": [
    "# Students with marks more than 80\n",
    "print(df[df['Marks'] > 80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are filtering out only those students who have scored more than 80 marks, similar to how you’d filter students manually in your notebook based on their marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Accessing with Conditions on Multiple Columns\n",
    "Let’s say you want to check who is above 18 years and scored more than 80 marks. Just like flipping through pages in your register, you can use multiple conditions to filter data.\n",
    "\n",
    "Example: Access based on multiple conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks\n",
      "2  Sameer   19     75\n"
     ]
    }
   ],
   "source": [
    "# Students older than 18 and marks more than 60\n",
    "result = df[(df['Age'] > 18) & (df['Marks'] > 60)]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've learned how to access data in a Pandas DataFrame using conditions and filter multiple columns, the next steps can involve more advanced data manipulation and analysis techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chaining Conditions\n",
    "Chaining conditions allows you to create more complex queries to filter your DataFrame based on multiple criteria.\n",
    "\n",
    "Example: Students Older Than 18 with Marks Greater Than 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks       City\n",
      "0   Rahul   18     85      Delhi\n",
      "1  Anjali   17     92     Mumbai\n",
      "2  Sameer   19     75  Bangalore\n",
      "3    Neha   18     88    Chennai\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha'],\n",
    "    'Age': [18, 17, 19, 18],\n",
    "    'Marks': [85, 92, 75, 88],\n",
    "    'City': ['Delhi', 'Mumbai', 'Bangalore', 'Chennai']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks       City\n",
      "2  Sameer   19     75  Bangalore\n"
     ]
    }
   ],
   "source": [
    "# Chaining conditions\n",
    "filtered_students = df[(df['Age'] > 18) & (df['Marks'] > 70)]\n",
    "print(filtered_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using isin() for Filtering\n",
    "The isin() function checks if each element in a DataFrame column is contained in a provided list. This is useful for filtering rows based on multiple possible values.\n",
    "\n",
    "Example: Filter Students from Specific Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks    City\n",
      "0   Rahul   18     85   Delhi\n",
      "1  Anjali   17     92  Mumbai\n"
     ]
    }
   ],
   "source": [
    "# Filtering students from Delhi and Mumbai\n",
    "filtered_cities = df[df['City'].isin(['Delhi', 'Mumbai'])]\n",
    "print(filtered_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using query() Method\n",
    "The query() method allows you to filter a DataFrame using a string expression. It provides a cleaner and more readable syntax, especially for complex conditions.\n",
    "\n",
    "Example: Query for Students Older Than 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks       City\n",
      "2  Sameer   19     75  Bangalore\n"
     ]
    }
   ],
   "source": [
    "# Using query to filter\n",
    "result = df.query('Age > 18 and Marks > 70')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sorting Data\n",
    "Sorting helps to arrange your DataFrame based on specific column values. This is useful for identifying top or bottom performers in your dataset.\n",
    "\n",
    "Example: Sort by Marks in Descending Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks       City\n",
      "1  Anjali   17     92     Mumbai\n",
      "3    Neha   18     88    Chennai\n",
      "0   Rahul   18     85      Delhi\n",
      "2  Sameer   19     75  Bangalore\n"
     ]
    }
   ],
   "source": [
    "# Sorting by Marks\n",
    "sorted_df = df.sort_values(by='Marks', ascending=False)\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also sort by multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks       City\n",
      "1  Anjali   17     92     Mumbai\n",
      "3    Neha   18     88    Chennai\n",
      "0   Rahul   18     85      Delhi\n",
      "2  Sameer   19     75  Bangalore\n"
     ]
    }
   ],
   "source": [
    "# Sort by Age, then by Marks\n",
    "sorted_df_multi = df.sort_values(by=['Age', 'Marks'], ascending=[True, False])\n",
    "print(sorted_df_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Group By Operations\n",
    "The groupby() function is powerful for aggregating data based on one or more columns. You can compute statistics like mean, sum, count, etc.\n",
    "\n",
    "Example: Group By City and Calculate Average Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City  Marks\n",
      "0  Bangalore   75.0\n",
      "1    Chennai   88.0\n",
      "2      Delhi   85.0\n",
      "3     Mumbai   92.0\n"
     ]
    }
   ],
   "source": [
    "# Group by City and calculate average Marks\n",
    "grouped_df = df.groupby('City')['Marks'].mean().reset_index()\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reset_index() method is used to convert the resulting series back into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Applying Functions with apply()\n",
    "The apply() function lets you apply a custom function across rows or columns. This is especially useful for data transformations.\n",
    "\n",
    "Example: Increase Marks by 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks       City  Updated Marks\n",
      "0   Rahul   18     85      Delhi             90\n",
      "1  Anjali   17     92     Mumbai             97\n",
      "2  Sameer   19     75  Bangalore             80\n",
      "3    Neha   18     88    Chennai             93\n"
     ]
    }
   ],
   "source": [
    "# Define a function to increase marks\n",
    "def increase_marks(marks):\n",
    "    return marks + 5\n",
    "\n",
    "# Apply the function to Marks column\n",
    "df['Updated Marks'] = df['Marks'].apply(increase_marks)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Handling Missing Data\n",
    "Missing data can skew your analysis, so handling it properly is crucial.\n",
    "\n",
    "Example: Dropping Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Marks     City  Updated Marks\n",
      "0   Rahul   18   85.0    Delhi             90\n",
      "1  Anjali   17   92.0   Mumbai             97\n",
      "3    Neha   18   88.0  Chennai             93\n"
     ]
    }
   ],
   "source": [
    "# Assuming there are missing values in the DataFrame\n",
    "df.loc[2, 'Marks'] = None  # Introduce a missing value for demonstration\n",
    "\n",
    "# Drop rows with any missing values\n",
    "cleaned_df = df.dropna()\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filling missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age      Marks       City  Updated Marks\n",
      "0   Rahul   18  85.000000      Delhi             90\n",
      "1  Anjali   17  92.000000     Mumbai             97\n",
      "2  Sameer   19  88.333333  Bangalore             80\n",
      "3    Neha   18  88.000000    Chennai             93\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and fill missing values without inplace\n",
    "df['Marks'] = df['Marks'].fillna(df['Marks'].mean())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Merging DataFrames\n",
    "Merging is similar to SQL joins. It’s useful when you have related datasets that you want to combine.\n",
    "\n",
    "Example: Merging Two DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age      Marks     City_x  Updated Marks     City_y\n",
      "0   Rahul   18  85.000000      Delhi             90      Delhi\n",
      "1  Anjali   17  92.000000     Mumbai             97     Mumbai\n",
      "2  Sameer   19  88.333333  Bangalore             80  Bangalore\n",
      "3    Neha   18  88.000000    Chennai             93    Chennai\n"
     ]
    }
   ],
   "source": [
    "# Create another DataFrame with City info\n",
    "data2 = {\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha'],\n",
    "    'City': ['Delhi', 'Mumbai', 'Bangalore', 'Chennai']\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Merge on Name\n",
    "merged_df = pd.merge(df, df2, on='Name')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concatenating DataFrames\n",
    "Concatenation is useful when you need to combine two or more DataFrames either vertically (stack rows) or horizontally (merge columns). You can use pd.concat() for this.\n",
    "\n",
    "Vertical Concatenation (Stacking DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Marks\n",
      "0   Rahul     85\n",
      "1  Anjali     92\n",
      "2  Sameer     75\n",
      "3    Neha     88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create two DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali'],\n",
    "    'Marks': [85, 92]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'Name': ['Sameer', 'Neha'],\n",
    "    'Marks': [75, 88]\n",
    "})\n",
    "\n",
    "# Concatenate vertically\n",
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horizontal Concatenation (Joining DataFrames by columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age    City  Marks\n",
      "0   Rahul   18   Delhi     85\n",
      "1  Anjali   17  Mumbai     92\n"
     ]
    }
   ],
   "source": [
    "# Create two DataFrames with the same index but different columns\n",
    "df3 = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali'],\n",
    "    'Age': [18, 17]\n",
    "})\n",
    "\n",
    "df4 = pd.DataFrame({\n",
    "    'City': ['Delhi', 'Mumbai'],\n",
    "    'Marks': [85, 92]\n",
    "})\n",
    "\n",
    "# Concatenate horizontally\n",
    "df_concat_horiz = pd.concat([df3, df4], axis=1)\n",
    "print(df_concat_horiz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GroupBy Operations\n",
    "groupby() is a powerful function that allows you to group data based on certain criteria, and then apply aggregate functions like mean(), sum(), count(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject\n",
      "Math       84.000000\n",
      "Science    81.666667\n",
      "Name: Marks, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha', 'Rahul', 'Sameer'],\n",
    "    'Subject': ['Math', 'Math', 'Math', 'Science', 'Science', 'Science'],\n",
    "    'Marks': [85, 92, 75, 88, 80, 77]\n",
    "})\n",
    "\n",
    "# Group by Subject and calculate the mean of Marks\n",
    "grouped = df.groupby('Subject')['Marks'].mean()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also group by multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name    Subject\n",
      "Anjali  Math       92\n",
      "Neha    Science    88\n",
      "Rahul   Math       85\n",
      "        Science    80\n",
      "Sameer  Math       75\n",
      "        Science    77\n",
      "Name: Marks, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group by Name and Subject, then calculate the sum of Marks\n",
    "grouped_multiple = df.groupby(['Name', 'Subject'])['Marks'].sum()\n",
    "print(grouped_multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pivot Tables\n",
    "Pivot tables allow you to reorganize and summarize data. They work similarly to pivot tables in Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject  Math  Science\n",
      "Name                  \n",
      "Anjali   92.0      NaN\n",
      "Neha      NaN     88.0\n",
      "Rahul    85.0      NaN\n",
      "Sameer    NaN     75.0\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha'],\n",
    "    'Subject': ['Math', 'Math', 'Science', 'Science'],\n",
    "    'Marks': [85, 92, 75, 88]\n",
    "})\n",
    "\n",
    "# Create a pivot table to summarize Marks by Subject and Name\n",
    "pivot_table = df.pivot_table(index='Name', columns='Subject', values='Marks', aggfunc='mean')\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reshaping Data (Melt and Pivot)\n",
    "Melt: Converts a DataFrame into a long format by unpivoting columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Subject  Marks\n",
      "0   Rahul     Math     85\n",
      "1  Anjali     Math     92\n",
      "2   Rahul  Science     88\n",
      "3  Anjali  Science     95\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali'],\n",
    "    'Math': [85, 92],\n",
    "    'Science': [88, 95]\n",
    "})\n",
    "\n",
    "# Melt the DataFrame to get a long format\n",
    "df_melt = pd.melt(df, id_vars=['Name'], var_name='Subject', value_name='Marks')\n",
    "print(df_melt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot: The opposite of melt, used to reshape data back into a wide format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject  Math  Science\n",
      "Name                  \n",
      "Anjali     92       95\n",
      "Rahul      85       88\n"
     ]
    }
   ],
   "source": [
    "# Pivot back to wide format\n",
    "df_pivot = df_melt.pivot(index='Name', columns='Subject', values='Marks')\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handling MultiIndex\n",
    "Pandas supports hierarchical indexing, or MultiIndex. This is useful when working with complex datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marks    85\n",
      "Name: (Rahul, Math), dtype: int64\n",
      "         Marks\n",
      "Subject       \n",
      "Math        85\n",
      "Science     88\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame with MultiIndex\n",
    "arrays = [\n",
    "    ['Rahul', 'Rahul', 'Anjali', 'Anjali'],\n",
    "    ['Math', 'Science', 'Math', 'Science']\n",
    "]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('Name', 'Subject'))\n",
    "\n",
    "df_multi = pd.DataFrame({'Marks': [85, 88, 92, 95]}, index=index)\n",
    "\n",
    "# Access data for Rahul's Math marks\n",
    "print(df_multi.loc[('Rahul', 'Math')])\n",
    "\n",
    "# Access all data for Rahul\n",
    "print(df_multi.loc['Rahul'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Filtering with query()\n",
    "The query() function provides a cleaner and faster way to filter rows based on conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Marks  Age\n",
      "1  Anjali     92   17\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha'],\n",
    "    'Marks': [85, 92, 75, 88],\n",
    "    'Age': [18, 17, 19, 18]\n",
    "})\n",
    "\n",
    "# Filter rows where Marks are greater than 80 and Age is less than 18\n",
    "df_filtered = df.query('Marks > 80 & Age < 18')\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Applying Custom Functions to DataFrames\n",
    "You can apply custom functions to rows or columns using the apply() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Marks  Age Performance\n",
      "0   Rahul     85   18        Good\n",
      "1  Anjali     92   17   Excellent\n",
      "2  Sameer     75   19        Good\n",
      "3    Neha     88   18        Good\n"
     ]
    }
   ],
   "source": [
    "# Custom function to classify students based on Marks\n",
    "def classify_marks(marks):\n",
    "    if marks >= 90:\n",
    "        return 'Excellent'\n",
    "    elif marks >= 75:\n",
    "        return 'Good'\n",
    "    else:\n",
    "        return 'Average'\n",
    "\n",
    "# Apply the function to the Marks column\n",
    "df['Performance'] = df['Marks'].apply(classify_marks)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dealing with Time-Series Data\n",
    "Pandas has robust support for time-series data. You can convert date columns to datetime and perform time-based indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Marks\n",
      "Date             \n",
      "2024-10-17     85\n",
      "2024-10-18     90\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame with date\n",
    "df = pd.DataFrame({\n",
    "    'Date': ['2024-10-17', '2024-10-18', '2024-10-19'],\n",
    "    'Marks': [85, 90, 88]\n",
    "})\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set Date as index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Filter data for a specific date range\n",
    "df_filtered = df.loc['2024-10-17':'2024-10-18']\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Concatenating DataFrames** \n",
    "\n",
    "Concatenation is like when you're combining two or more tables either row-wise or column-wise. Think of it like stacking notebooks on top of each other or side by side.\n",
    "\n",
    "#### Vertical Concatenation (Stacking Rows)\n",
    "Suppose you have marks data from two classes. You want to combine them so that you can see all the students' marks in one DataFrame.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Class 1 data\n",
    "df1 = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali'],\n",
    "    'Marks': [85, 92]\n",
    "})\n",
    "\n",
    "# Class 2 data\n",
    "df2 = pd.DataFrame({\n",
    "    'Name': ['Sameer', 'Neha'],\n",
    "    'Marks': [75, 88]\n",
    "})\n",
    "\n",
    "# Concatenating vertically (stacking rows)\n",
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(df_concat)\n",
    "```\n",
    "This code stacks both classes' data together, as if you’re merging two lists of students into one.\n",
    "\n",
    "#### Horizontal Concatenation (Adding Columns)\n",
    "Now, let's say you have separate tables for names and cities, and you want to add the cities next to the names, just like you're adding an extra column in your Excel sheet.\n",
    "\n",
    "```python\n",
    "# Names and Age\n",
    "df3 = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali'],\n",
    "    'Age': [18, 17]\n",
    "})\n",
    "\n",
    "# Cities and Marks\n",
    "df4 = pd.DataFrame({\n",
    "    'City': ['Delhi', 'Mumbai'],\n",
    "    'Marks': [85, 92]\n",
    "})\n",
    "\n",
    "# Concatenate horizontally (adding columns)\n",
    "df_concat_horiz = pd.concat([df3, df4], axis=1)\n",
    "print(df_concat_horiz)\n",
    "```\n",
    "Here, we are combining two DataFrames column-wise. It’s like writing each student's name on one side of the sheet and their city on the other side.\n",
    "\n",
    "### 2. **GroupBy Operations**\n",
    "\n",
    "Grouping is like organizing data based on a key or category. Suppose you want to group students by their subjects and then calculate the average marks of each group.\n",
    "\n",
    "```python\n",
    "# Sample DataFrame with subjects\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha', 'Rahul', 'Sameer'],\n",
    "    'Subject': ['Math', 'Math', 'Math', 'Science', 'Science', 'Science'],\n",
    "    'Marks': [85, 92, 75, 88, 80, 77]\n",
    "})\n",
    "\n",
    "# Group by Subject and calculate the average Marks\n",
    "grouped = df.groupby('Subject')['Marks'].mean()\n",
    "print(grouped)\n",
    "```\n",
    "Grouping helps in organizing large datasets, just like we separate students into different sections or batches and calculate class averages.\n",
    "\n",
    "#### Grouping by Multiple Columns:\n",
    "Sometimes you may want to group students by both **Name** and **Subject**, and see their total marks for each subject.\n",
    "\n",
    "```python\n",
    "# Group by both Name and Subject\n",
    "grouped_multiple = df.groupby(['Name', 'Subject'])['Marks'].sum()\n",
    "print(grouped_multiple)\n",
    "```\n",
    "This method is useful when you have more complex categories to analyze, like in school records when you want to know each student's performance across subjects.\n",
    "\n",
    "### 3. **Pivot Tables** \n",
    "\n",
    "Pivot tables are like the tables we make when we want to summarize data. It helps in seeing the data from a different angle. \n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha'],\n",
    "    'Subject': ['Math', 'Math', 'Science', 'Science'],\n",
    "    'Marks': [85, 92, 75, 88]\n",
    "})\n",
    "\n",
    "# Create pivot table showing Marks for each Subject and Name\n",
    "pivot_table = df.pivot_table(index='Name', columns='Subject', values='Marks', aggfunc='mean')\n",
    "print(pivot_table)\n",
    "```\n",
    "In this example, we are summarizing the marks of each student based on their subjects, much like how a school report card summarizes subject-wise marks for each student.\n",
    "\n",
    "### 4. **Reshaping Data: Melting and Pivoting**\n",
    "\n",
    "#### **Melt**: \n",
    "Melting is when you convert a wide format table into a long format. Suppose you have multiple columns (like \"Math Marks\" and \"Science Marks\") and you want them in one single column as \"Subject\" and another for \"Marks\".\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali'],\n",
    "    'Math': [85, 92],\n",
    "    'Science': [88, 95]\n",
    "})\n",
    "\n",
    "# Melt to long format\n",
    "df_melt = pd.melt(df, id_vars=['Name'], var_name='Subject', value_name='Marks')\n",
    "print(df_melt)\n",
    "```\n",
    "This is like converting multiple rows into one compact format, where each row now represents one subject and its corresponding marks.\n",
    "\n",
    "#### **Pivot**: \n",
    "Pivoting is the reverse of melting. You take a long-form DataFrame and turn it back into a wide form.\n",
    "\n",
    "```python\n",
    "# Pivot back to wide format\n",
    "df_pivot = df_melt.pivot(index='Name', columns='Subject', values='Marks')\n",
    "print(df_pivot)\n",
    "```\n",
    "This is like rearranging data back into its original format. Pivoting is often used when you want to see the broader view of your data, like putting marks back into subject-wise columns.\n",
    "\n",
    "### 5. **MultiIndex (Hierarchical Indexing)**\n",
    "\n",
    "MultiIndexing is like when you have two levels of indexing. It helps in managing complex data with two (or more) levels of categorization.\n",
    "\n",
    "```python\n",
    "arrays = [\n",
    "    ['Rahul', 'Rahul', 'Anjali', 'Anjali'],\n",
    "    ['Math', 'Science', 'Math', 'Science']\n",
    "]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('Name', 'Subject'))\n",
    "\n",
    "df_multi = pd.DataFrame({'Marks': [85, 88, 92, 95]}, index=index)\n",
    "\n",
    "# Accessing specific data\n",
    "print(df_multi.loc[('Rahul', 'Math')])\n",
    "\n",
    "# Accessing all data for 'Rahul'\n",
    "print(df_multi.loc['Rahul'])\n",
    "```\n",
    "In this example, we are using two levels for our data: the student's name and the subject they studied. This allows us to easily access specific rows based on multiple conditions.\n",
    "\n",
    "### 6. **Advanced Filtering with `query()`**\n",
    "\n",
    "Instead of using complex conditions with brackets (`&`, `|`), Pandas provides a cleaner way to filter data with `query()`.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha'],\n",
    "    'Marks': [85, 92, 75, 88],\n",
    "    'Age': [18, 17, 19, 18]\n",
    "})\n",
    "\n",
    "# Filter students with Marks greater than 80 and Age less than 18\n",
    "df_filtered = df.query('Marks > 80 & Age < 18')\n",
    "print(df_filtered)\n",
    "```\n",
    "This method allows you to filter data in a very human-readable form, just like asking a question or giving instructions like \"Give me students who scored more than 80 and are younger than 18\".\n",
    "\n",
    "### 7. **Custom Functions with `apply()`**\n",
    "\n",
    "Sometimes, basic functions aren't enough, and you need to apply custom logic. For example, classifying students based on their marks.\n",
    "\n",
    "```python\n",
    "def classify_marks(marks):\n",
    "    if marks >= 90:\n",
    "        return 'Excellent'\n",
    "    elif marks >= 75:\n",
    "        return 'Good'\n",
    "    else:\n",
    "        return 'Average'\n",
    "\n",
    "# Apply custom function\n",
    "df['Performance'] = df['Marks'].apply(classify_marks)\n",
    "print(df)\n",
    "```\n",
    "Here, we are assigning students a performance label based on their marks. `apply()` allows you to add your own logic, just like applying your own judgment criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Advanced Data Cleaning Techniques\n",
    "You’ve touched upon basic data cleaning. Let's now explore more sophisticated techniques for handling messy datasets.\n",
    "\n",
    "Detecting and Handling Outliers: Outliers can heavily influence your data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Name, Marks, Age]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha'],\n",
    "    'Marks': [85, 100, 400, 88],\n",
    "    'Age': [18, 17, 19, 18]\n",
    "})\n",
    "\n",
    "# Using Z-Score to identify outliers\n",
    "from scipy import stats\n",
    "z_scores = np.abs(stats.zscore(df['Marks']))\n",
    "df_outliers = df[z_scores > 3]  # Marks with z-score > 3 are considered outliers\n",
    "print(df_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers often distort data, so this method is useful for identifying extreme deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation Techniques: Beyond filling missing values with mean(), we can use more intelligent methods like interpolation and forward-filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_38804\\2053570204.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Marks'] = df['Marks'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "df['Marks'] = df['Marks'].interpolate(method='linear')\n",
    "df['Marks'] = df['Marks'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Window Functions (Rolling, Expanding, and EWMA)\n",
    "Window functions help compute moving averages or cumulative sums, which is useful in time series analysis. This gives a deeper understanding of data trends and smoothing techniques.\n",
    "\n",
    "Rolling Window: Moving averages and other aggregations over a rolling window of time or data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Marks  Rolling_Avg\n",
      "0     88          NaN\n",
      "1     85          NaN\n",
      "2     92    88.333333\n",
      "3     75    84.000000\n",
      "4     89    85.333333\n",
      "5     91    85.000000\n",
      "6     94    91.333333\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Marks': [88, 85, 92, 75, 89, 91, 94]\n",
    "})\n",
    "\n",
    "# Rolling average over a window of 3 values\n",
    "df['Rolling_Avg'] = df['Marks'].rolling(window=3).mean()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding Window: Cumulative operations across all previous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding cumulative sum of marks\n",
    "df['Expanding_Sum'] = df['Marks'].expanding(min_periods=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     88.0\n",
       "1    173.0\n",
       "2    265.0\n",
       "3    340.0\n",
       "4    429.0\n",
       "5    520.0\n",
       "6    614.0\n",
       "Name: Expanding_Sum, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Expanding_Sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponentially Weighted Moving Average (EWMA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EWMA for smoother data trends\n",
    "df['EWMA'] = df['Marks'].ewm(span=3, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    88.000000\n",
       "1    86.500000\n",
       "2    89.250000\n",
       "3    82.125000\n",
       "4    85.562500\n",
       "5    88.281250\n",
       "6    91.140625\n",
       "Name: EWMA, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EWMA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merging Techniques: Complex Joins and Merging on Indexes\n",
    "You’ve already covered basic merging, but let’s explore more complex joins and how to merge on indexes or using conditions:\n",
    "\n",
    "Merging on Indexes: Sometimes, you need to merge based on the DataFrame's index rather than a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Marks       City\n",
      "Rahul      85      Delhi\n",
      "Anjali     92     Mumbai\n",
      "Sameer     75  Bangalore\n",
      "Neha       88    Chennai\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'Marks': [85, 92, 75, 88]\n",
    "}, index=['Rahul', 'Anjali', 'Sameer', 'Neha'])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'City': ['Delhi', 'Mumbai', 'Bangalore', 'Chennai']\n",
    "}, index=['Rahul', 'Anjali', 'Sameer', 'Neha'])\n",
    "\n",
    "# Merge on index\n",
    "df_merged = df1.merge(df2, left_index=True, right_index=True)\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining on Conditions: When the merging key is not identical between datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Marks Student       City\n",
      "0   Rahul     85   Rahul      Delhi\n",
      "1  Anjali     92     NaN        NaN\n",
      "2  Sameer     75  Sameer  Bangalore\n",
      "3    Neha     88     NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "df_left = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha'],\n",
    "    'Marks': [85, 92, 75, 88]\n",
    "})\n",
    "\n",
    "df_right = pd.DataFrame({\n",
    "    'Student': ['Rahul', 'Sameer'],\n",
    "    'City': ['Delhi', 'Bangalore']\n",
    "})\n",
    "\n",
    "# Conditional join\n",
    "df_joined = df_left.merge(df_right, left_on='Name', right_on='Student', how='left')\n",
    "print(df_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Data Manipulation\n",
    "Handling time-based data in Pandas is essential, especially for datasets involving dates and times, like stock prices, sales data, etc.\n",
    "\n",
    "Datetime Index: Convert a column to a datetime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Date': ['2024-10-17', '2024-10-18', '2024-10-19'],\n",
    "    'Marks': [85, 90, 95]\n",
    "})\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-17</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-18</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-19</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Marks\n",
       "Date             \n",
       "2024-10-17     85\n",
       "2024-10-18     90\n",
       "2024-10-19     95"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling: Aggregating time-based data into different periods (e.g., monthly, weekly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Marks\n",
      "Date             \n",
      "2024-10-17     85\n",
      "2024-10-18     90\n",
      "2024-10-19     95\n"
     ]
    }
   ],
   "source": [
    "# Resample data by day and calculate the sum\n",
    "df_resampled = df.resample('D').sum()\n",
    "print(df_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting and Lagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifting marks data to compare today with yesterday\n",
    "df['Previous_Day_Marks'] = df['Marks'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marks</th>\n",
       "      <th>Previous_Day_Marks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-17</th>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-18</th>\n",
       "      <td>90</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-19</th>\n",
       "      <td>95</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Marks  Previous_Day_Marks\n",
       "Date                                 \n",
       "2024-10-17     85                 NaN\n",
       "2024-10-18     90                85.0\n",
       "2024-10-19     95                90.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Indexing: Multi-level Indexing Operations\n",
    "Working with multi-level indices allows more complex slicing and selection operations.\n",
    "\n",
    "Accessing Data in Multi-level Indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Marks\n",
      "Subject       \n",
      "Math        85\n",
      "Marks    85\n",
      "Name: (Delhi, Math), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'City': ['Delhi', 'Mumbai', 'Bangalore', 'Chennai'],\n",
    "    'Subject': ['Math', 'Math', 'Science', 'Science'],\n",
    "    'Marks': [85, 92, 88, 75]\n",
    "})\n",
    "df.set_index(['City', 'Subject'], inplace=True)\n",
    "\n",
    "# Access data using Multi-level index\n",
    "print(df.loc['Delhi'])\n",
    "print(df.loc[('Delhi', 'Math')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Section (xs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Marks\n",
      "City         \n",
      "Delhi      85\n",
      "Mumbai     92\n"
     ]
    }
   ],
   "source": [
    "# Get data for a specific level\n",
    "print(df.xs('Math', level='Subject'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced DataFrame Aggregation Techniques\n",
    "Beyond the simple mean, sum, and count operations, you can apply custom aggregation functions across different columns.\n",
    "\n",
    "Custom Aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Marks        \n",
      "         mean max min\n",
      "Subject              \n",
      "Math     88.5  92  85\n",
      "Science  81.5  88  75\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Subject': ['Math', 'Math', 'Science', 'Science'],\n",
    "    'Marks': [85, 92, 88, 75]\n",
    "})\n",
    "\n",
    "# Applying custom aggregations\n",
    "custom_agg = df.groupby('Subject').agg({\n",
    "    'Marks': ['mean', 'max', 'min']\n",
    "})\n",
    "print(custom_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Aggregations on Different Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Marks     Age    \n",
      "         mean max min max\n",
      "Subject                  \n",
      "Math     88.5  92  16  17\n",
      "Science  81.5  88  16  18\n"
     ]
    }
   ],
   "source": [
    "df['Age'] = [16, 17, 18, 16]\n",
    "custom_multi_agg = df.groupby('Subject').agg({\n",
    "    'Marks': ['mean', 'max'],\n",
    "    'Age': ['min', 'max']\n",
    "})\n",
    "print(custom_multi_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Plotting with Pandas\n",
    "Pandas allows for basic plotting, but you can take it a step further with customization using Matplotlib under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rahul', 'Anjali', 'Sameer', 'Neha'],\n",
    "    'Marks': [85, 92, 75, 88]\n",
    "})\n",
    "\n",
    "# Plotting marks\n",
    "df.plot(kind='bar', x='Name', y='Marks', color='skyblue')\n",
    "plt.title('Students Marks Comparison')\n",
    "plt.xlabel('Student Name')\n",
    "plt.ylabel('Marks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Working with Large Datasets: Performance Optimization\n",
    "When handling large datasets, performance becomes critical. Let's explore methods to optimize memory usage and computation time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory Optimization with dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('large_data.csv', dtype={'Marks': 'int16'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using chunk_size to Process Large Files in Batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data in chunks of 1000 rows at a time\n",
    "chunk_size = 1000\n",
    "for chunk in pd.read_csv('large_data.csv', chunksize=chunk_size):\n",
    "    process(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pandas Extensions: df.pipe() for Clean Workflow\n",
    "The pipe() function in Pandas helps chain operations cleanly, making your code more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_percentage(df):\n",
    "    df['Percentage'] = df['Marks'] / df['Marks'].max() * 100\n",
    "    return df\n",
    "\n",
    "# Use pipe to apply functions in sequence\n",
    "df = (df.pipe(add_percentage)\n",
    "        .pipe(lambda x: x.assign(Passed=lambda df: df['Marks'] > 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rahul</td>\n",
       "      <td>85</td>\n",
       "      <td>92.391304</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anjali</td>\n",
       "      <td>92</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sameer</td>\n",
       "      <td>75</td>\n",
       "      <td>81.521739</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neha</td>\n",
       "      <td>88</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Marks  Percentage  Passed\n",
       "0   Rahul     85   92.391304    True\n",
       "1  Anjali     92  100.000000    True\n",
       "2  Sameer     75   81.521739    True\n",
       "3    Neha     88   95.652174    True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
