{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Advanced Indexing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiIndex (Hierarchical Indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, imagine this. Let’s say you have a school, and under each class, you have sections like ‘A’ and ‘B’. Similarly, in Pandas, we can have data indexed in multiple levels, like Class and Section. This is called MultiIndexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a MultiIndex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 6  A    50\n",
      "         B    60\n",
      "Class 7  A    55\n",
      "         B    65\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's create some multi-level data\n",
    "arrays = [\n",
    "    ['Class 6', 'Class 6', 'Class 7', 'Class 7'],\n",
    "    ['A', 'B', 'A', 'B']\n",
    "]\n",
    "\n",
    "# Now we create a Series with this multi-level index\n",
    "multi_index_series = pd.Series([50, 60, 55, 65], index=arrays)\n",
    "print(multi_index_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, just like how you have different classes and sections, we have two levels of indexes. Now, when you want to pull out marks from \"Class 6, Section A,\" it's super easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accessing MultiIndex Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(multi_index_series['Class 6']['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, think of it as having a multi-level key to access specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vectorized String Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like how we handle strings in Python, Pandas lets you do fancy string operations but in bulk (imagine operating on an entire column of names, rather than one name at a time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting text to uppercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      RAM\n",
      "1    SHYAM\n",
      "2    GEETA\n",
      "3     SITA\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "names = pd.Series(['ram', 'shyam', 'geeta', 'sita'])\n",
    "\n",
    "# Convert all names to uppercase\n",
    "print(names.str.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, all the names are instantly converted to uppercase. Similarly, you can split strings, replace parts of strings, or even check for patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking for presence of a substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(names.str.contains('am'))  # Checks if 'am' is in the string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are checking if 'am' is present in the names. Simple and quick!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Handling Large Data with Memory Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with really large data, like population data of India (imagine crores of rows!), Pandas can get a bit slow. But don’t worry, there are ways to handle this efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Downcasting data types to save memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -15536\n",
      "1    -5536\n",
      "2     4464\n",
      "3    14464\n",
      "dtype: int16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Series with large integers\n",
    "big_data = pd.Series([50000, 60000, 70000, 80000])\n",
    "\n",
    "# Downcasting to smaller types\n",
    "smaller_data = big_data.astype(np.int16)\n",
    "print(smaller_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, by converting the data to int16 (which uses less memory compared to the default int64), you are saving memory space, making the program run faster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Working with Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "India has multiple festivals, holidays, and special occasions. What if we want to analyze data based on dates? Pandas has powerful tools for handling time-based data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-15    100\n",
      "2024-10-16    120\n",
      "2024-10-17    130\n",
      "2024-10-18    115\n",
      "2024-10-19    140\n",
      "Freq: D, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a date range\n",
    "dates = pd.date_range('2024-10-15', periods=5)\n",
    "\n",
    "# Creating a time-based Series\n",
    "time_series = pd.Series([100, 120, 130, 115, 140], index=dates)\n",
    "print(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have a Series where the index is dates, perfect for working with data that changes over time, like stock prices or rainfall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resampling Time Series Data (changing frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-20    605\n",
      "Freq: W-SUN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Resample the data to get weekly sums\n",
    "weekly_data = time_series.resample('W').sum()\n",
    "print(weekly_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Applying Custom Functions (Map, Apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say you want to apply a function to each value of the Series. Pandas gives you powerful tools like .apply() and .map() for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applying custom functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50\n",
      "1    89\n",
      "2    81\n",
      "3    70\n",
      "4    90\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Marks of students\n",
    "marks = pd.Series([45, 89, 76, 65, 90])\n",
    "\n",
    "# Let's apply a function to give bonus marks\n",
    "def bonus_marks(mark):\n",
    "    return mark + 5 if mark < 80 else mark\n",
    "\n",
    "new_marks = marks.apply(bonus_marks)\n",
    "print(new_marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, students with less than 80 marks got a bonus of 5, just like how schools sometimes give grace marks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Using groupby for Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you're working on a school's data, and you want to group students by class and calculate the average marks for each class. The groupby() function in Pandas helps with this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grouping data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "6th    85.0\n",
      "7th    77.5\n",
      "8th    95.0\n",
      "Name: Marks, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = {'Class': ['6th', '6th', '7th', '7th', '8th'],\n",
    "        'Marks': [80, 90, 85, 70, 95]}\n",
    "\n",
    "marks_df = pd.DataFrame(data)\n",
    "\n",
    "# Group by 'Class' and calculate the average marks\n",
    "grouped = marks_df.groupby('Class')['Marks'].mean()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. .rolling() for Moving Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful when working with continuous data like stock prices or rainfall data.\n",
    "\n",
    "- Calculating a rolling average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           NaN\n",
      "1           NaN\n",
      "2    105.000000\n",
      "3    111.666667\n",
      "4    113.333333\n",
      "5    121.666667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "stock_prices = pd.Series([100, 110, 105, 120, 115, 130])\n",
    "\n",
    "# Calculate a 3-day rolling average\n",
    "rolling_avg = stock_prices.rolling(window=3).mean()\n",
    "print(rolling_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Advanced Data Cleaning (Replacing & Interpolation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we deal with data, it's often messy, just like how you have to clean your study table! Sometimes you need to replace or fill missing values cleverly.\n",
    "\n",
    "- Replacing specific values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    90.0\n",
      "1    48.6\n",
      "2    85.0\n",
      "3    48.6\n",
      "4    70.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "marks = pd.Series([90, -1, 85, -1, 70])\n",
    "\n",
    "# Replace -1 (missing marks) with the average marks\n",
    "marks_replaced = marks.replace(-1, marks.mean())\n",
    "print(marks_replaced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now take the advanced concepts in Pandas Series and break them down further using even more relatable analogies and simplified techniques. I'll focus on making it super easy to understand, while incorporating some unique tips and tricks along the way.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. MultiIndex (Hierarchical Indexing) - Simplified**\n",
    "\n",
    "Think of MultiIndex as a way of **organizing data in layers**, like organizing a school’s data by class and then by section.\n",
    "\n",
    "#### **How to Create and Use MultiIndex**\n",
    "\n",
    "Here’s how you can think of it: imagine you’re a class teacher and you’re responsible for marks in **multiple sections** of multiple classes. You have the data like this:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Multi-level data (Class and Section)\n",
    "data = pd.Series(\n",
    "    [75, 82, 78, 91], \n",
    "    index=[['Class 6', 'Class 6', 'Class 7', 'Class 7'], ['A', 'B', 'A', 'B']]\n",
    ")\n",
    "\n",
    "print(data)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Class 6  A    75\n",
    "          B    82\n",
    "Class 7  A    78\n",
    "          B    91\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Explanation**: \n",
    "- \"Class 6\" and \"Class 7\" are your **primary labels** (like the first level of the hierarchy).\n",
    "- \"A\" and \"B\" are **secondary labels** (like sections).\n",
    "\n",
    "#### **Accessing MultiIndex Data**\n",
    "\n",
    "If you want to **pull out marks for Class 6, Section A**, think of it as asking for the **class and section** together. Here’s how you access that:\n",
    "\n",
    "```python\n",
    "print(data['Class 6']['A'])  # Output: 75\n",
    "```\n",
    "\n",
    "You can also slice through multiple levels to grab all the data for an entire class:\n",
    "\n",
    "```python\n",
    "print(data['Class 6'])  # Output: A    75, B    82\n",
    "```\n",
    "\n",
    "**Tip**: **MultiIndexing** helps in handling complicated datasets that have multiple categories!\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Advanced String Operations – With Real-world Analogy**\n",
    "\n",
    "Let’s say you’re handling names in a school. You’ve been given a list of names that need to be **uniformly formatted**, such as converting them to uppercase, finding patterns, or splitting names. This can be done all at once with **vectorized string operations** in Pandas!\n",
    "\n",
    "#### **Example: Convert Names to Uppercase**\n",
    "\n",
    "Let’s take some students’ names:\n",
    "\n",
    "```python\n",
    "names = pd.Series(['ram', 'shyam', 'geeta', 'sita'])\n",
    "print(names.str.upper())\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "0      RAM\n",
    "1    SHYAM\n",
    "2    GEETA\n",
    "3     SITA\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "Now all the names are uppercase, just like how a teacher would want names in a **uniform format** for a school roster.\n",
    "\n",
    "#### **Check if a Substring is Present**\n",
    "\n",
    "Let’s say you want to know if a name contains the substring \"am\" (like checking for \"ram\" and \"shyam\"). Here’s how you can do it:\n",
    "\n",
    "```python\n",
    "print(names.str.contains('am'))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "0     True\n",
    "1     True\n",
    "2    False\n",
    "3    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "This gives you a **True** or **False** value for each name, depending on whether \"am\" is present.\n",
    "\n",
    "#### **Tip**: You can even use `.str.split()` to break names into first and last names!\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Memory Optimization – How to Think About It**\n",
    "\n",
    "Think of your computer’s memory as a school bus. If you’re transporting students (data), you want to use the smallest bus possible to save fuel (memory). If you can fit students into a smaller bus (smaller data type), it’s more efficient!\n",
    "\n",
    "#### **Downcasting Data Types**\n",
    "\n",
    "Pandas usually stores integers in `int64` by default, which is like using a giant bus for a small group of students. But you can **downcast** them to `int16` or even `int8` if the values are small.\n",
    "\n",
    "```python\n",
    "big_data = pd.Series([100, 200, 300, 400])\n",
    "# Downcast to int16 to save memory\n",
    "optimized_data = big_data.astype('int16')\n",
    "print(optimized_data)\n",
    "```\n",
    "\n",
    "This way, you save memory and make your operations faster, especially when handling **crores of rows**!\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Time Series Data – Relating to Real-life Events**\n",
    "\n",
    "In India, we have many festivals like Diwali, Holi, and Eid. Let’s say you want to track how the prices of sweets change during these festivals. Pandas has built-in tools to handle **time-based data**.\n",
    "\n",
    "#### **Creating a Time Series**\n",
    "\n",
    "```python\n",
    "dates = pd.date_range('2024-10-15', periods=5)\n",
    "time_series = pd.Series([100, 150, 130, 180, 200], index=dates)\n",
    "print(time_series)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "2024-10-15    100\n",
    "2024-10-16    120\n",
    "2024-10-17    130\n",
    "2024-10-18    115\n",
    "2024-10-19    140\n",
    "Freq: D, dtype: int64\n",
    "```\n",
    "\n",
    "You now have a **time-based index** where you can analyze data **over time**, like tracking prices or daily stock levels.\n",
    "\n",
    "#### **Resampling (Converting Daily Data to Weekly)**\n",
    "\n",
    "What if you want to analyze weekly trends instead of daily? You can **resample** the data to a weekly frequency:\n",
    "\n",
    "```python\n",
    "weekly_data = time_series.resample('W').sum()\n",
    "print(weekly_data)\n",
    "```\n",
    "\n",
    "This will give you the total prices for each week.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Applying Custom Functions – Giving \"Grace Marks\"**\n",
    "\n",
    "Sometimes, you may want to give bonus marks to students scoring below 80 (like **grace marks**). Here’s how you apply custom logic to a Series using `.apply()`:\n",
    "\n",
    "```python\n",
    "marks = pd.Series([45, 89, 76, 65, 90])\n",
    "\n",
    "# Function to add bonus marks\n",
    "def bonus_marks(mark):\n",
    "    return mark + 5 if mark < 80 else mark\n",
    "\n",
    "# Apply the bonus to all students\n",
    "new_marks = marks.apply(bonus_marks)\n",
    "print(new_marks)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "0    50\n",
    "1    89\n",
    "2    81\n",
    "3    70\n",
    "4    90\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "This applies a **custom function** to each element, just like how a teacher would give additional marks based on certain conditions.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Grouping Data – Just Like Calculating Class-wise Averages**\n",
    "\n",
    "Imagine a scenario where you want to calculate the **average marks for each class**. You can use Pandas' `.groupby()` function to group and analyze the data.\n",
    "\n",
    "```python\n",
    "data = {'Class': ['6th', '6th', '7th', '7th', '8th'],\n",
    "        'Marks': [80, 90, 85, 70, 95]}\n",
    "marks_df = pd.DataFrame(data)\n",
    "\n",
    "# Group by 'Class' and calculate average marks\n",
    "grouped = marks_df.groupby('Class')['Marks'].mean()\n",
    "print(grouped)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Class\n",
    "6th    85.0\n",
    "7th    77.5\n",
    "8th    95.0\n",
    "Name: Marks, dtype: float64\n",
    "```\n",
    "\n",
    "This groups the data by class and finds the **average marks** for each class.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. `.rolling()` – Calculating Moving Averages**\n",
    "\n",
    "In finance or stock markets, people often use **moving averages** to smooth out fluctuations. You can do the same with Pandas using `.rolling()`.\n",
    "\n",
    "#### **Calculate a 3-day Moving Average**\n",
    "\n",
    "```python\n",
    "stock_prices = pd.Series([100, 110, 105, 120, 115, 130])\n",
    "\n",
    "# 3-day rolling average\n",
    "rolling_avg = stock_prices.rolling(window=3).mean()\n",
    "print(rolling_avg)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "0      NaN\n",
    "1      NaN\n",
    "2    105.0\n",
    "3    111.7\n",
    "4    113.3\n",
    "5    121.7\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Just like how we calculate averages over time to see trends, `.rolling()` helps you smooth out the noise in data.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Advanced Data Cleaning – Fixing Missing Values**\n",
    "\n",
    "Sometimes your data might have missing or incorrect values, like in exam marks where some students didn’t show up. You can clean this data using `.replace()` or `.interpolate()`.\n",
    "\n",
    "#### **Replacing Missing Values with Mean**\n",
    "\n",
    "Let’s say some marks are missing (`-1` indicates missing marks). You want to replace them with the **average marks**.\n",
    "\n",
    "```python\n",
    "marks = pd.Series([90, -1, 85, -1, 70])\n",
    "\n",
    "# Replace -1 with the average\n",
    "marks_filled = marks.replace(-1, marks.mean())\n",
    "print(marks_filled)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "0    90.0\n",
    "1    81.7\n",
    "2    85.0\n",
    "3    81.7\n",
    "4    70.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Now the missing values are replaced with the **average**, which is often how schools handle incomplete data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
